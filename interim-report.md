### Interim Report

**Abstract**

*THIS IS SOMETHING YOU TYPICALLY WRITE LAST*

**1. Introduction and Motivation**

*THIS IS SOMETHING YOU TYPICALLY WRITE LAST*

**1.1. Motivation**

*TODO: PERHAPS WRITE MOTIVATION BEFORE WRITING THE INTRODUCTION*

*Should these be two separate sections?*

**2. Research Questions**

Within this section two sets of research questions are presented. Firstly, a set of research questions that are addressed within this report is provided (§2.1). Secondly, a set of future research questions to be addressed within the concluding report is offered (§2.2). Thereafter, the aims and objectives of the proposed research questions are probed (§2.3). Finally, a set of hypotheses is given.

**2.1. Interim Research Questions**

Using the methodology outlined within §4.x. the following research questions are investigated within this report:

1. How do differences in similarity **(NOTE: IT MAY BE BE GOOD TO LINK TO A SECTION THAT DOCUMENTS SOME KIND OF SIMILARITY METRIC BETWEEN DATA INSTANCES WITHIN EACH DATASET)** between datasets affect the performance (generalisation, accuracy and error) of fairly simple convolutional neural network architectures (as outlined in §4.x)?
2. How does reducing the size of a training dataset affect the performance of fairly simple convolutional neural network architectures?

Research question 2. is already well researched within the literature [INSERT CITATIONS HERE]. However, the question links into our future research questions (§2.2) associated with using techniques {footnote: such as transfer learning and deep feature extraction} to improve the performance of small datasets on neural network architectures. For this reason, it is important that a investigation is conducted in order to establish a more conclusive understanding of the proposed datasets (§3) on our employed architecture, outlined in §4.x..

**2.2. Future Research Questions**

* How does transfer learning 

*TODO: expand on this*

**2.3. Aims and Objectives**

To try and find a good method of improving performance on the same task using a smaller version of the same dataset in combination with techniques.

*TODO: expand on this*

**2.4. Hypotheses**

* Datasets with subtle differences between classes will perform worse on classification tasks than datasets with obvious differences between classes using the proposed convolution neural network architecture (§4.x.).
* Reducing the size of the training dataset will result in worse generalisation using the proposed network architecture (§4.x.).
* Reducing the size of the training dataset will result in an overfitting of the network architecture to the subsampled dataset. **TODO: NOTE: THIS MAY NEED ADDITIONAL CLARIFICATION.**
* **TODO: ADD FURTHER HYPOTHESES**

**3. Data Set and Task**

* http://cvit.iiit.ac.in/projects/IMFDB/ (Faces database)
* https://www.kaggle.com/zalando-research/fashionmnist (Clothes database)

**4. Methodology**

**TODO**

**5. Baseline Experiments**

*prerequisite: experimental results*

**5.1. Further Experiments**

*TODO*

**6. Interim Conclusions**

*prerequisite: experimental results from §5.*

**7. Future Work**

* Apply techniques such as deep feature extraction and transfer learning (we could try transferring from ImageNet, perhaps?)

**7.1. Backup Plans**

*TODO*