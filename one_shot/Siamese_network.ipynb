{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import random\n",
    "import scipy.misc\n",
    "import os\n",
    "import numpy.random as rng\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import scipy\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten, MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23111489"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##VGG16 augmented siamese network\n",
    "w_init=keras.initializers.RandomNormal(mean=0.0, stddev=0.2, seed=10)\n",
    "b_init=keras.initializers.RandomNormal(mean=0.5, stddev=0.01, seed=10)\n",
    "input_shape = (64,64,3)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "VGG=VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(64,64,3), pooling=None)\n",
    "model = Sequential()\n",
    "for l in VGG.layers:\n",
    "    model.add(l)\n",
    "model.add(Flatten(input_shape=VGG.output_shape[1:]))\n",
    "model.add(Dense(4096, activation='sigmoid',kernel_regularizer=l2(0.01),kernel_initializer=w_init,bias_initializer=b_init))\n",
    "first_twin = model(left_input)\n",
    "second_twin = model(right_input)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[19:20]:\n",
    "    layer.trainable = True\n",
    "L1_layer =Lambda(lambda x: K.abs(x[0]-x[1]))\n",
    "L1_distance = L1_layer([first_twin, second_twin])\n",
    "prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "#optimizer=optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False )\n",
    "optimizer = keras.optimizers.Adam(0.00006)\n",
    "siamese_net.compile(optimizer=optimizer, loss=\"binary_crossentropy\")\n",
    "siamese_net.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_6\n",
      "1 block1_conv1\n",
      "2 block1_conv2\n",
      "3 block1_pool\n",
      "4 block2_conv1\n",
      "5 block2_conv2\n",
      "6 block2_pool\n",
      "7 block3_conv1\n",
      "8 block3_conv2\n",
      "9 block3_conv3\n",
      "10 block3_pool\n",
      "11 block4_conv1\n",
      "12 block4_conv2\n",
      "13 block4_conv3\n",
      "14 block4_pool\n",
      "15 block5_conv1\n",
      "16 block5_conv2\n",
      "17 block5_conv3\n",
      "18 block5_pool\n",
      "19 flatten_2\n",
      "20 dense_1\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0=os.path.join(os.getcwd() +'/face/train_split_rgb/0/' )\n",
    "class1=os.path.join(os.getcwd() +'/face/train_split_rgb/1/' )\n",
    "class2=os.path.join(os.getcwd() +'/face/train_split_rgb/2/' )\n",
    "class3=os.path.join(os.getcwd() +'/face/train_split_rgb/3/' )\n",
    "class4=os.path.join(os.getcwd() +'/face/train_split_rgb/4/' )\n",
    "class5=os.path.join(os.getcwd() +'/face/train_split_rgb/5/' )\n",
    "class6=os.path.join(os.getcwd() +'/face/train_split_rgb/6/' )\n",
    "#50% same 50% different class ,randomly sampled pairs.\n",
    "#Ensured 6 images from each class used in training.\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = scipy.misc.imread(os.path.join(folder,filename))\n",
    "        images.append(img)\n",
    "    return images\n",
    "Train_image=[load_images(class0),load_images(class1),load_images(class2),load_images(class3), \\\n",
    "            load_images(class4),load_images(class5),load_images(class6)]\n",
    "\n",
    "\"\"\"Create batch of 42 training pairs, 21 pairs with same class, 21 pairs with different class\"\"\"\n",
    "batch_size=42\n",
    "w, h = 64,64\n",
    "pairs=[np.zeros((batch_size, w, h,3)) for i in range(2)]\n",
    "twin1_catagories_1=np.array([0,0,0,1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,6,6,6])\n",
    "catagory_11=twin1_catagories_1  #for simplification purposes\n",
    "twin1_catagories_2=np.array([5, 1, 1, 0, 0, 4, 6, 3, 4, 6, 4, 2, 2, 2, 5, 3, 6, 3, 0, 1, 5])\n",
    "catagory_12=twin1_catagories_2  #for simplification purposes\n",
    "twin2_catagories=twin1_catagories_1\n",
    "\"np.random.seed(10)\"\n",
    "\"idx=np.random.choice(6000,42,replace=False)\"\n",
    "\"Code commented are implemented separately to avoid fixed seed for random processes in future codes.\"\n",
    "\n",
    "idx=[1789, 5566, 1657, 3983, 5619, 1933,  449,  492, 1172, 2040, 1638,\n",
    "2864,   43, 5540, 3758, 5606, 4936, 3399, 5436, 2602,  708, 4879,\n",
    "5593, 4736, 1324,  952, 3036, 4971, 2630, 2543, 4627, 1044,  502,\n",
    "1477, 5107, 4155, 2501, 3975,  143, 2083, 2514, 2569]\n",
    "b=list(np.arange(0,6000))\n",
    "for i in idx:\n",
    "    b.remove(i)\n",
    "\n",
    "\n",
    "\"Since we are only using 42 pairs of photos, we can treat remaning entire training images as validation set. There is now\"\n",
    "\"two separate dataset for training and validation.\"\n",
    "\n",
    "\n",
    "def load_batch_train_pairs(batch_size):\n",
    "    targets=np.zeros((batch_size,))\n",
    "    targets[batch_size//2:] = 1\n",
    "    for i in range(42):\n",
    "        if i<batch_size//2:\n",
    "            pairs[0][i,:,:,:]=Train_image[catagory_11[i]][idx[i]]\n",
    "            pairs[1][i,:,:,:]=Train_image[catagory_12[i]][idx[i]]\n",
    "        if i>=batch_size//2:\n",
    "            pairs[0][i,:,:,:]=Train_image[catagory_11[i-(batch_size//2)]][idx[i]] \n",
    "            pairs[1][i,:,:,:]=Train_image[catagory_11[i-(batch_size//2)]][idx[i-(batch_size//2)]]\n",
    "    return pairs,targets\n",
    "def get_one_shot(N):\n",
    "    \"N = no.of class/N classes to distinguish from\"\n",
    "    categories = rng.choice(range(7),size=(N,),replace=False)            \n",
    "    true_category = categories[0]\n",
    "    index=rng.choice(b,replace=False,size=(N,))\n",
    "    ex1, ex2 = rng.choice(b,replace=False,size=(2,))\n",
    "    test_image_set = np.asarray([Train_image[true_category][ex1]]*N)\n",
    "    support_set=np.zeros((N,64,64,3))\n",
    "    for i in range(1,N):\n",
    "        support_set[i,:,:,:] = Train_image[categories[i]][index[i]]\n",
    "        support_set[0,:,:,:] = Train_image[true_category][ex2]\n",
    "    targets = np.zeros((N,))\n",
    "    targets[0] = 1\n",
    "    targets, test_image_set, support_set = shuffle(targets, test_image_set, support_set) #Shuffle and give the same random orders of \n",
    "    #correct & incorrect pairs in three sets. \n",
    "    pairs = [test_image_set,support_set]\n",
    "    return pairs,targets\n",
    "def oneshot_accuracy(model,k,N,verbose=0):\n",
    "    \"Calculation for accuracy of one-shot task to validation/test set after training the model\"\n",
    "    n_correct=0\n",
    "    if verbose:\n",
    "        print(\"Evaluating model on {} random {} way one-shot learning tasks ...\".format(k,N))\n",
    "    for i in range(k):\n",
    "        inputs,targets=get_one_shot(N)\n",
    "        probs = model.predict(inputs)\n",
    "        if np.argmax(probs) == np.argmax(targets):\n",
    "                n_correct+=1\n",
    "    percent_correct = (100.0*n_correct / k)\n",
    "    if verbose:\n",
    "        print(\"Got an average of {}% over {} random {} way few-shot learning accuracy\".format(percent_correct,k,N))\n",
    "    return percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/42 [==============================] - 6s 151ms/step - loss: 6710.5049\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 6s 139ms/step - loss: 6710.4990\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 6s 138ms/step - loss: 6710.4941\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 6s 140ms/step - loss: 6710.4883\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 6s 138ms/step - loss: 6710.4839\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 6s 140ms/step - loss: 6710.4795\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 6710.4746\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 6s 144ms/step - loss: 6710.4707\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 7s 155ms/step - loss: 6710.4668\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 6s 152ms/step - loss: 6710.4629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe43ccbfba8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Training Siamese network:\"\n",
    "siamese_net.fit(x=load_batch_train_pairs(42)[0],y=load_batch_train_pairs(42)[1],batch_size=42,epochs=10,validation_data=None,verbose=1)\n",
    "#for i in range(epochs):\n",
    "#    val_acc = oneshot_accuracy(siamese_net,N_way,n_val,verbose=True)\n",
    "#val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on 200 random 7 way one-shot learning tasks ...\n",
      "Got an average of 16.5% over 200 random 7 way few-shot learning accuracy\n",
      "16.5\n"
     ]
    }
   ],
   "source": [
    "val_acc = oneshot_accuracy(siamese_net,200,7,verbose=True)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=np.array([0,0,0,1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,6,6,6])\n",
    "c=np.array([0,0,0,1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,6,6,6])\n",
    "d=np.array([5, 1, 1, 0, 0, 4, 6, 3, 4, 6, 4, 2, 2, 2, 5, 3, 6, 3, 0, 1, 5])\n",
    "for i in range(21):\n",
    "    while c[i] == b[i]:\n",
    "        np.random.shuffle(c)\n",
    "c\n",
    "#targets=np.zeros((42,))\n",
    "#targets[21//2:] = 1\n",
    "#targets\n",
    "b==d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iterations\n",
    "for i in range(1, n_iter):\n",
    "    (inputs,targets)=train_pairs(batch_size)\n",
    "    loss=model.train_on_batch(inputs,targets)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1789, 5566, 1657, 3983, 5619, 1933,  449,  492, 1172, 2040, 1638,\n",
       "       2864,   43, 5540, 3758, 5606, 4936, 3399, 5436, 2602,  708, 4879,\n",
       "       5593, 4736, 1324,  952, 3036, 4971, 2630, 2543, 4627, 1044,  502,\n",
       "       1477, 5107, 4155, 2501, 3975,  143, 2083, 2514, 2569])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "np.random.choice(6000,42,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-1d24b58863eb>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-1d24b58863eb>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print(:-i)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i in range(42):\n",
    "    if i>=42//2:\n",
    "        print(batch_size//2)i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
