{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D , Dense, Activation, MaxPooling2D,Flatten\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import argparse\n",
    "\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(file_train, file_test, size=1.0):\n",
    "    # loadtxt gives results with that b' char\n",
    "    # data_train = np.loadtxt(file_train, dtype='str', delimiter=',')\n",
    "    # data_test = np.loadtxt(file_test, dtype='str', delimiter=',')\n",
    "\n",
    "    data_train = np.genfromtxt(file_train, dtype='str', delimiter=',')\n",
    "    data_test = np.genfromtxt(file_test, dtype='str', delimiter=',')\n",
    "\n",
    "    xtr, ytr = data_train[:,1], data_train[:,0].astype(int)\n",
    "    xva, yva = data_test[:,1], data_test[:,0].astype(int)\n",
    "\n",
    "    # use 15% of train data for testing\n",
    "    xtr, xte, ytr, yte = train_test_split(xtr, ytr, test_size=0.30)\n",
    "\n",
    "    if size >= 1.0 and size <=0:\n",
    "        return xtr, ytr, xva, yva, xte, yte\n",
    "    \n",
    "    discard_size = 1.0 - size\n",
    "    xtr, _, ytr, _ = train_test_split(xtr, ytr, test_size=discard_size)\n",
    "    #xva, _, yva, _ = train_test_split(xva, yva, test_size=discard_size)\n",
    "    xte, _, yte, _ = train_test_split(xte, yte, test_size=discard_size)\n",
    "    \n",
    "    xtr, ytr = reshape_dataset(xtr, ytr.ravel())\n",
    "    xva, yva = reshape_dataset(xva, yva.ravel())\n",
    "    xte, yte = reshape_dataset(xte, yte.ravel())\n",
    "\n",
    "    return xtr, ytr, xva, yva, xte, yte\n",
    "\n",
    "def reshape_dataset(x, y):\n",
    "    # make sure classes are between 0 and num_classes\n",
    "    new_y = np.ones_like(y)*(-1)\n",
    "    num_classes = np.unique(y)\n",
    "    for idx, label in enumerate(num_classes):\n",
    "        new_y[y == label] = idx\n",
    "    \n",
    "    y = to_categorical(new_y)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def get_model_1(learning_rate):\n",
    "    VGG=VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(64,64,3), pooling=None)\n",
    "    model = Sequential()\n",
    "    for l in VGG.layers:\n",
    "        model.add(l)\n",
    "    #model.add(Flatten(input_shape=VGG.output_shape[1:]))    \n",
    "    model.add(Flatten())    \n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for layer in model.layers[19:20]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    optimizers.SGD(lr=learning_rate, momentum=0.0, decay=0.0, nesterov=False )\n",
    "    model.compile(optimizer='SGD', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def save_plot_metrics(log_file_name, history):\n",
    "    keys = history.history.keys()\n",
    "\n",
    "    f, ax = plt.subplots(len(keys), 1, figsize=(5, 22))\n",
    "\n",
    "    for idx, k in enumerate(keys):\n",
    "        ax[idx].plot(history.history[k])\n",
    "        ax[idx].set_title(\"model \" + k)\n",
    "        ax[idx].set_ylabel(k)\n",
    "        ax[idx].set_xlabel('epoch')\n",
    "    \n",
    "    f.savefig(\"{:s}.png\".format(log_file_name), dpi=90)\n",
    "\n",
    "def save_log_metrics(log_file_name, hyper, history):\n",
    "    header = \"\"\n",
    "\n",
    "    for key in hyper:\n",
    "        header = header + \", \" + key + \": \" + str(hyper[key])\n",
    "\n",
    "    header = header[2:]\n",
    "\n",
    "    with open(log_file_name + \".txt\", \"w+\") as log_file:\n",
    "        log_file.write(header+\"\\n\")\n",
    "        \n",
    "        keys = history.history.keys()\n",
    "        head = \"\"\n",
    "        \n",
    "        c = 0\n",
    "        for k in keys:\n",
    "            if c == 0:\n",
    "                l = len(history.history[k]) # number of epochs\n",
    "                h = np.zeros(l)\n",
    "            head = head + k + \",\"\n",
    "            h = np.vstack((h, history.history[k]))\n",
    "            c = c + 1\n",
    "\n",
    "        head = head[:-1]\n",
    "        head = head + \"\\n\"\n",
    "        log_file.write(head)\n",
    "\n",
    "        h = h[1:,:]\n",
    "        h = h.T\n",
    "\n",
    "        for row in h:\n",
    "            new_line = \"\"\n",
    "            for value in row:\n",
    "                new_line = new_line + \"{:.8f},\".format(value)\n",
    "            new_line = new_line[:-1]\n",
    "            new_line = new_line + \"\\n\"\n",
    "            log_file.write(new_line)\n",
    "\n",
    "    log_file.close()\n",
    "\n",
    "def get_images(paths):\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for image_path in paths:\n",
    "        image_path = \"../data\"+image_path[1:]\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        images.append(image)\n",
    "\n",
    "    return np.array(images)\n",
    "\n",
    "def load_clothes(size=1.0):\n",
    "    return load_dataset(\"../data/clothes_train.txt\", \"../data/clothes_test.txt\", size)\n",
    "    \n",
    "def load_faces(size=1.0):\n",
    "    return load_dataset(\"../data/faces_train.txt\", \"../data/face_test.txt\", size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, hyper):\n",
    "    training_size = hyper[\"training_size\"]\n",
    "    batch_size = hyper[\"batch_size\"]\n",
    "    num_epochs = hyper[\"num_epochs\"]\n",
    "    dataset = hyper[\"dataset_type\"]\n",
    "    dataset_size = hyper[\"dataset_size\"]\n",
    "\n",
    "    log_file_name = generate_log_file_name(hyper)\n",
    "\n",
    "    if dataset == 1:\n",
    "        xtr, ytr, xva, yva, xte, yte = load_clothes(dataset_size / 100.0)\n",
    "    elif dataset_type == 2:\n",
    "        xtr, ytr, xva, yva, xte, yte = load_faces(dataset_size / 100.0)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    xtr = get_images(xtr)\n",
    "    xte = get_images(xte)\n",
    "    xva = get_images(xva)\n",
    "    \n",
    "    history = model.fit(\n",
    "        xtr,\n",
    "        ytr,\n",
    "        batch_size,\n",
    "        validation_data = (xva, yva),\n",
    "        epochs=num_epochs\n",
    "    )\n",
    "\n",
    "    eval_ = model.evaluate(xte, yte)\n",
    "    for val, key in zip(eval_, model.metrics_names):\n",
    "        hyper[key] = val\n",
    "\n",
    "    save_log_metrics(log_file_name, hyper, history)\n",
    "    save_plot_metrics(log_file_name, history)\n",
    "    model.save_weights(log_file_name + \".hdf\")\n",
    "\n",
    "def generate_log_file_name(hyper):\n",
    "    exp_name = hyper[\"exp_name\"]\n",
    "    model_type = hyper[\"model_type\"]\n",
    "    \n",
    "    dataset_type = hyper[\"dataset_type\"]\n",
    "    if dataset_type == 1:\n",
    "        dataset_name = \"clothes\"\n",
    "    elif dataset_type == 2:\n",
    "        dataset_name = \"faces\"\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    dataset_size = hyper[\"dataset_size\"]\n",
    "    return \"{:s}_model_{:d}_{:s}_{:d}\".format(exp_name, model_type, dataset_name, dataset_size)\n",
    "\n",
    "def train_networks(exp_name, model_type, learning_rate, training_size, batch_size, num_epochs, dataset_size, dataset_type):\n",
    "    model = None\n",
    "\n",
    "    if model_type == 1:\n",
    "        model = get_model_1(learning_rate)\n",
    "        model.summary()\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    hyper = OrderedDict()\n",
    "    hyper[\"learning_rate\"] = learning_rate\n",
    "    hyper[\"training_size\"] = training_size\n",
    "    hyper[\"batch_size\"] = batch_size\n",
    "    hyper[\"num_epochs\"] = num_epochs\n",
    "    hyper[\"dataset_type\"] = dataset_type\n",
    "    hyper[\"dataset_size\"] = dataset_size\n",
    "    hyper[\"model_type\"] = model_type\n",
    "    hyper[\"exp_name\"] = exp_name\n",
    "\n",
    "    train_model(model, hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 7)                 14343     \n",
      "=================================================================\n",
      "Total params: 14,729,031\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,729,031\n",
      "_________________________________________________________________\n",
      "Train on 294 samples, validate on 7000 samples\n",
      "Epoch 1/10\n",
      "294/294 [==============================] - 232s - loss: 11.2415 - acc: 0.1531 - val_loss: 10.6349 - val_acc: 0.1467\n",
      "Epoch 2/10\n",
      "294/294 [==============================] - 228s - loss: 11.2415 - acc: 0.1531 - val_loss: 10.6349 - val_acc: 0.1467\n",
      "Epoch 3/10\n",
      "294/294 [==============================] - 231s - loss: 11.2415 - acc: 0.1531 - val_loss: 10.6349 - val_acc: 0.1467\n",
      "Epoch 4/10\n",
      "294/294 [==============================] - 229s - loss: 11.2415 - acc: 0.1531 - val_loss: 10.6349 - val_acc: 0.1467\n",
      "Epoch 5/10\n",
      "294/294 [==============================] - 230s - loss: 11.2415 - acc: 0.1531 - val_loss: 10.6349 - val_acc: 0.1467\n",
      "Epoch 6/10\n",
      "250/294 [========================>.....] - ETA: 1s - loss: 11.2892 - acc: 0.1560"
     ]
    }
   ],
   "source": [
    "train_networks(\"test\", 1, 0.001, 2000, 50, 10, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35693 images belonging to 7 classes.\n",
      "Found 6307 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "ImgGen=ImageDataGenerator()\n",
    "train_gen=ImgGen.flow_from_directory( '../baseline/face/train_split_0.85',target_size=(64,64),batch_size=32,color_mode=\"grayscale\",\n",
    "                                    shuffle=False)\n",
    "valid_gen=ImgGen.flow_from_directory( '../baseline/face/valid_split_0.15',target_size=(64,64),batch_size=32,color_mode=\"grayscale\",\n",
    "                                    shuffle=False)\n",
    "tf.image.grayscale_to_rgb(\n",
    "    train_gen,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The input must have 3 channels; got `input_shape=(64, 64, 1)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b0f859082a57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#model.compile(optimizer='Adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mVGG\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mVGG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/keras/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    104\u001b[0m                                       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                                       \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                                       weights=weights)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36m_obtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                     raise ValueError('The input must have 3 channels; got '\n\u001b[0;32m--> 293\u001b[0;31m                                      '`input_shape=' + str(input_shape) + '`')\n\u001b[0m\u001b[1;32m    294\u001b[0m                 if ((input_shape[0] is not None and input_shape[0] < min_size) or\n\u001b[1;32m    295\u001b[0m                    (input_shape[1] is not None and input_shape[1] < min_size)):\n",
      "\u001b[0;31mValueError\u001b[0m: The input must have 3 channels; got `input_shape=(64, 64, 1)`"
     ]
    }
   ],
   "source": [
    "\n",
    "#model = Sequential()\n",
    "#model.add(Conv2D(10,5,strides=(1,1) ,padding=\"valid\",input_shape=(64,64,1), kernel_initializer='random_uniform', bias_initializer='zeros' ))\n",
    "#model.add(MaxPooling2D(pool_size=(3, 3),padding='valid'))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv2D(5,5,strides=1,padding='valid'))\n",
    "#model.add(MaxPooling2D(pool_size=(3, 3),padding='valid'))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(7, activation='softmax'))\n",
    "#optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)  \n",
    "#model.compile(optimizer='Adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "VGG=VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(64,64,1), pooling=None)\n",
    "model = Sequential()\n",
    "for l in VGG.layers:\n",
    "    model.add(l)\n",
    "model.add(Flatten(input_shape=VGG.output_shape[1:]))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[19:20]:\n",
    "    layer.trainable = True\n",
    "optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False )\n",
    "model.compile(optimizer='SGD', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit_generator(\n",
    "        train_gen,\n",
    "        steps_per_epoch=1000,\n",
    "        epochs=10,\n",
    "        validation_data=valid_gen,\n",
    "        verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_4\n",
      "1 block1_conv1\n",
      "2 block1_conv2\n",
      "3 block1_pool\n",
      "4 block2_conv1\n",
      "5 block2_conv2\n",
      "6 block2_pool\n",
      "7 block3_conv1\n",
      "8 block3_conv2\n",
      "9 block3_conv3\n",
      "10 block3_pool\n",
      "11 block4_conv1\n",
      "12 block4_conv2\n",
      "13 block4_conv3\n",
      "14 block4_pool\n",
      "15 block5_conv1\n",
      "16 block5_conv2\n",
      "17 block5_conv3\n",
      "18 block5_pool\n"
     ]
    }
   ],
   "source": [
    "# 40% for training and 60% for validation \n",
    "#Epoch 1/10\n",
    "#2000/2000 [==============================] - 156s 78ms/step - loss: 0.6978 - acc: 0.7422 - val_loss: 0.0068 - val_acc: 0.9997\n",
    "#Epoch 2/10\n",
    "#2000/2000 [==============================] - 152s 76ms/step - loss: 0.0456 - acc: 0.9879 - val_loss: 0.0046 - val_acc: 0.9995\n",
    "#Epoch 3/10\n",
    "# 157/2000 [=>............................] - ETA: 1:55 - loss: 0.0036 - acc: 0.9998\n",
    "#\n",
    "for i, layer in enumerate(model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False )\n",
    "model.compile(optimizer='SGD', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit_generator(\n",
    "        train_gen,\n",
    "        steps_per_epoch=1000,\n",
    "        epochs=10,\n",
    "        validation_data=valid_gen,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
