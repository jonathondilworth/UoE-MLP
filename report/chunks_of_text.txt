
Furthermore, the proposed neural network architecture (\ref{sec:arch}) is assumed to be fairly standard. Therefore we assume a degree of generalisation to similar problem domains in any further research. However, more work may need to be undertaken in order to validate this (\ref{sec:future}).

 \item If time permits, how does one shot learning (the use of siamese network architectures \cite{bromley1994signature}\cite{oslsiamese}) perform on small datasets within classification tasks?


 \subsection{Aims and Objectives}
\label{sec:objectives}

The core objective of the concluding report is to investigate connectionist based methodologies for improving classification performance on vision based tasks using small datasets. Initially, this investigation will be addressed by obtaining a set of baseline classification accuracies using a shallow convolutional neural network architecture. Baseline accuracies will be obtained for training dataset sizes of: 100\%, 75\%, 50\%, 25\%, 10\%, 1\%.

As an optional objective, the interim report (in conjunction with the concluding report) aims to investigate how subtlety between different classes (given the same sized dataset) affects the performance of the proposed network architecture (\ref{sec:arch}).

 \item \label{h:3} Reducing the size of the training dataset will result in an overfitting of the network architecture to the subsampled dataset.
  \item \label{h:4} The application of transfer learning using a pre-trained model (any ImageNet variant) will result in improved model performance.


Within the experiments presented within this report, two datasets were utilised. As explained within the introduction (\ref{sec:intro}), the first dataset (the fashionmnist dataset) contains obvious differences between images in the dataset. Whereas the second dataset (facial expressionn database) contains subtle differences between instances of data.



In the second stage, two different transfer learning methods will be studied to examine potential methods to improve performances given very small dataset which is frequent in real-world scenarios. First, we transfer a very large pre-trained network VGG16 on our aforementioned baseline system with pre-trained weights on small dataset. Since VGG16 trains on 200 types of general objects. The generality of the model might be beneficial to train on common objects (clothes dataset). Apart from transferring model to domain-specific dataset (clothes dataset). We also transfer the model to dataset with unrelated and subtle differences between classes in the dataset (facial dataset), to test the effectiveness of pre-trained model on task that shares little similarity with the pre-trained model. 

Besides transferring pre-trained model, we also wish to investigate the effect of one-shot learning on small dataset. To demonstrate a basic version of one-shot learning we will implement Siamese network on either one of the dataset( clothes/facial expression) with the help of existing models and our modification to these models , due to time constrain and taking potential difficulty of implementing one-shot learning architecture from scratch. As a backup plan, we will abandon this experiment and focus more on transferring models methods.